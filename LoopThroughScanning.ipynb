{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_arrays(SR, SB, gaiadata2):\n",
    "    X = SR[:,3]-center_ra\n",
    "    Y = SR[:,2]-center_dec\n",
    "\n",
    "    Xb = SB[:,3]-center_ra\n",
    "    Yb = SB[:,2]-center_dec\n",
    "    \n",
    "    Xad = gaiadata2[:, 3]-center_ra\n",
    "    Yad = gaiadata2[:, 2]-center_dec\n",
    "\n",
    "    SR = np.c_[SR[:,0],SR[:,1],X, Y, SR[:,4],SR[:,5]]\n",
    "    SB = np.c_[SB[:,0],SB[:,1],Xb, Yb, SB[:,4],SB[:,5]]\n",
    "    gaiadata2 = np.c_[gaiadata2[:,0],gaiadata2[:,1], Xad, Yad, gaiadata2[:,4],gaiadata2[:,5]]\n",
    "    \n",
    "    return SR, SB, gaiadata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_arr_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diff(SR, SB):\n",
    "    return abs(len(SR) - len(SB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_SR_SB_pointers(pointers, increment, data_arr, start_point, end_point):\n",
    "    SR = data_arr[(data_arr[:,0] > pointers[1])*(data_arr[:,0] < pointers[2])]\n",
    "    SB = data_arr[(data_arr[:,0] > pointers[0])*(data_arr[:,0] < pointers[1]) + (data_arr[:,0] > pointers[2])*(data_arr[:,0] < pointers[3])]\n",
    "\n",
    "    previous_diff = calc_diff(SR, SB)\n",
    "    prev_SR, prev_SB = SR, SB\n",
    "    curr_diff = previous_diff\n",
    "    bottom_bool = False\n",
    "    top_bool = True\n",
    "\n",
    "    while curr_diff <= previous_diff and pointers[3] < end_point:\n",
    "        previous_diff, prev_SR, prev_SB = curr_diff, SR, SB\n",
    "        if bottom_bool:\n",
    "            pointers[0] = max(start_point, pointers[0] - increment)\n",
    "        else:\n",
    "            pointers[3] = min(end_point, pointers[3] + increment)\n",
    "        bottom_bool, top_bool = top_bool, bottom_bool\n",
    "        SR = data_arr[(data_arr[:,0] > pointers[1])*(data_arr[:,0] < pointers[2])]\n",
    "        SB = data_arr[(data_arr[:,0] > pointers[0])*(data_arr[:,0] < pointers[1]) + (data_arr[:,0] > pointers[2])*(data_arr[:,0] < pointers[3])]\n",
    "        curr_diff = calc_diff(SR, SB)\n",
    "\n",
    "    return prev_SR, prev_SB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(SR, SB, num_models, all_data, pointers, colors, filename, iter_num):\n",
    "    \n",
    "    X = np.concatenate([SR,SB])\n",
    "    Y = np.concatenate([np.ones(len(SR)),np.zeros(len(SB))])\n",
    "\n",
    "    myscalar = preprocessing.StandardScaler()\n",
    "    myscalar.fit(X)\n",
    "    X_scaled = myscalar.transform(X)\n",
    "    all_data_scaled = myscalar.transform(all_data)\n",
    "\n",
    "    X_scaled = X_scaled[Y<2]\n",
    "    Y = Y[Y<2]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.5)\n",
    "\n",
    "\n",
    "    for i in range(num_models):\n",
    "        \n",
    "        print('working')\n",
    "\n",
    "        #set biases for each layer, bias_initializer\n",
    "        #initializers.GlorotNormal()\n",
    "        model = Sequential()\n",
    "        initializer =tf.keras.initializers.glorot_normal()\n",
    "        model.add(Dense(64, input_dim=5, activation='relu', bias_initializer = initializer)) \n",
    "        model.add(Dense(64, activation='relu', bias_initializer = initializer))\n",
    "        model.add(Dense(64, activation='relu', bias_initializer = initializer))\n",
    "        model.add(Dense(1, activation='sigmoid', bias_initializer = initializer))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        history = model.fit(X_train[:,1:],Y_train, epochs=20, batch_size=200,validation_data=(X_test[:,1:],Y_test), verbose = 0) \n",
    "\n",
    "        preds = model.predict(X_test[:,1:], batch_size=int(0.1*len(X_test)))\n",
    "        preds_all = model.predict(all_data_scaled[:, 1:]) \n",
    "        \n",
    "        #cut on color\n",
    "        cuts = [0.,0.5,0.9,0.99, 0.999]\n",
    "        bins_cuts = np.zeros((len(cuts), 99))\n",
    "        \n",
    "        plt.figure(figsize = (12, 12))\n",
    "        plt.yscale('log')\n",
    "        plt.ylim([1, 10e5])\n",
    "        plt.axvline(pointers[1], color = 'black')\n",
    "        plt.axvline(pointers[2], color = 'black')\n",
    "        plt.axvline(pointers[0], color = 'gray')\n",
    "        plt.axvline(pointers[3], color = 'gray')\n",
    "        title_str = 'Cuts on pmdec'\n",
    "        plt.ylabel('Counts', fontsize = 20)\n",
    "        plt.xlabel('PMDEC', fontsize= 20)\n",
    "#         stars_near_zero = []\n",
    "        stars_passing_cut = []\n",
    "        for j in range(len(cuts)):\n",
    "            cut = cuts[j]\n",
    "            X_unscaled = myscalar.inverse_transform(X_scaled[:, :6])\n",
    "            all_data_unscaled = myscalar.inverse_transform(all_data_scaled[:, :6])\n",
    "            #fix below line\n",
    "            #all_data_unscaled_with_cut = all_data_unscaled[(all_data_unscaled[:,4]>0.5) * (all_data_unscaled[:,4]<1)]\n",
    "            #X_pass_all_with_cut = all_data_unscaled_with_cut[(preds_all[:,0] > np.quantile(preds[Y_test==1],[cut])[0])]\n",
    "            \n",
    "            X_pass_all = all_data_unscaled[(preds_all[:,0] > np.quantile(preds[Y_test==1],[cut])[0]) * (all_data_unscaled[:,4]>0.5) * (all_data_unscaled[:,4]<1)]\n",
    "#             X_pass_all = all_data_unscaled[(preds_all[:,0] > np.quantile(preds[Y_test==1],[cut])[0])]\n",
    "            plt.hist(X_pass_all[:,0], bins = np.linspace(-30, 15, 100), color = colors[j], alpha = 1, histtype = 'step', label = str(cut*100) + 'th Percentile')\n",
    "            if cut == 0.99:\n",
    "#                 stars_near_zero = X_pass_all[(X_pass_all[:,0] >-1) * (X_pass_all[:,0] <1)]\n",
    "                stars_passing_cut = X_pass_all[(X_pass_all[:,0] > pointers[1]) * (X_pass_all[:,0] < pointers[2])]\n",
    "        plt.text((pointers[1] + pointers[2])/2, 1e5, 'SR', fontsize = 20)\n",
    "        plt.legend()\n",
    "        plt.savefig('figures_fjorm_radec_cut/scanning_plots' + filename[28:].replace('.', '_') + '_' + str(iter_num) + '.pdf')\n",
    "        plt.clf()\n",
    "        \n",
    "#         plt.figure(figsize = (12, 12))\n",
    "#         plt.hist2d(stars_near_zero[:,3],stars_near_zero[:,2],bins=[np.linspace(-15,15,100),np.linspace(-15,15,100)])\n",
    "#         plt.savefig('figures_fjorm_radec_cut/stars_near_zero_2dhist' + filename[28:].replace('.', '_') + '_' + str(iter_num) + '.pdf')\n",
    "#         plt.clf()\n",
    "        \n",
    "        plt.figure(figsize = (12, 12))\n",
    "        plt.hist2d(stars_passing_cut[:,3],stars_passing_cut[:,2],bins=[np.linspace(-15,15,100),np.linspace(-15,15,100)])\n",
    "        plt.savefig('figures_fjorm_radec_cut/stars_passing_cut' + filename[28:].replace('.', '_') + '_' + str(iter_num) + '.pdf')\n",
    "        plt.clf()\n",
    "        \n",
    "#         plt.figure(figsize = (12, 12))\n",
    "#         plt.yscale('log')\n",
    "#         plt.ylim([1, 10e5])\n",
    "#         plt.ylabel('Counts', fontsize = 20)\n",
    "#         plt.xlabel('PMRA', fontsize= 20)\n",
    "#         plt.hist(stars_near_zero[:,1], bins = np.linspace(-30, 15, 100), alpha = 1, histtype = 'step', label = '99th Percentile')\n",
    "#         plt.savefig('figures_fjorm_radec_cut/stars_near_zero_rahist' + filename[28:].replace('.', '_') + '_' + str(iter_num) + '.pdf')\n",
    "#         plt.clf()\n",
    "        \n",
    "        plt.figure(figsize = (12, 12))\n",
    "        plt.yscale('log')\n",
    "        plt.ylim([1, 10e5])\n",
    "        plt.ylabel('Counts', fontsize = 20)\n",
    "        plt.xlabel('PMRA', fontsize= 20)\n",
    "        plt.hist(stars_passing_cut[:,1], bins = np.linspace(-30, 15, 100), alpha = 1, histtype = 'step', label = '99th Percentile')\n",
    "        plt.savefig('figures_fjorm_radec_cut/stars_passing_cut_rahist' + filename[28:].replace('.', '_') + '_' + str(iter_num) + '.pdf')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_and_plot(gaiadata2, filename):\n",
    "    iter_num = 0\n",
    "    start_point = min(gaiadata2[:,0])\n",
    "    pointers = np.zeros(4)\n",
    "    signal_size = 4\n",
    "    signal_increment = 2\n",
    "    sb_start_diff = 0.5\n",
    "    pointers[0] = start_point\n",
    "    pointers[1] = start_point + sb_start_diff\n",
    "    pointers[2] = pointers[1] + signal_size\n",
    "    pointers[3] = pointers[2] + sb_start_diff\n",
    "    end_point = max(gaiadata2[:,0])\n",
    "    colors = ['red', 'orange', 'green', 'blue', 'purple']\n",
    "\n",
    "    while pointers[3] <= end_point:\n",
    "        SR, SB = find_SR_SB_pointers(pointers, sb_start_diff, gaiadata2, start_point, end_point)\n",
    "        if len(SR) >= threshold_arr_size:\n",
    "            SR, SB, all_data = build_data_arrays(SR, SB, gaiadata2)\n",
    "            build_model(SR, SB, 1, all_data, pointers, colors, filename, iter_num)\n",
    "            iter_num += 1\n",
    "        pointers[1] += signal_increment\n",
    "        pointers[2] += signal_increment\n",
    "        pointers[0] = pointers[1] - sb_start_diff\n",
    "        pointers[3] = pointers[2] + sb_start_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_data(filename, gaiadata2):\n",
    "    if filename == \"/data1/users/bpnachman/gaia/gaiascan_l315.0_b66.4_ra197.7_dec4.0.npy\":\n",
    "        gaiadata2 = gaiadata2[gaiadata2[:,3] < 13]\n",
    "    elif filename == \"/data1/users/bpnachman/gaia/gaiascan_l101.2_b58.4_ra212.7_dec55.2.npy\":\n",
    "        gaiadata2 = gaiadata2[gaiadata2[:,3] < 12]\n",
    "    elif filename == \"/data1/users/bpnachman/gaia/gaiascan_l22.5_b74.4_ra209.6_dec23.3.npy\":\n",
    "        gaiadata2 = gaiadata2[((gaiadata2[:,3] < -6) + (gaiadata2[:,3] > -4)) * ((gaiadata2[:,3] < 4) + (gaiadata2[:,3] > 6))]\n",
    "    elif filename == \"/data1/users/bpnachman/gaia/gaiascan_l337.5_b74.4_ra201.9_dec14.0.npy\":\n",
    "        gaiadata2 = gaiadata2[((gaiadata2[:,3] < 3) + (gaiadata2[:,3] > 5)) * (gaiadata2[:,3] < 14)]\n",
    "    elif filename == \"/data1/users/bpnachman/gaia/gaiascan_l45.0_b82.2_ra201.5_dec28.5.npy\":\n",
    "        gaiadata2 = gaiadata2[((gaiadata2[:,3] < -12) + (gaiadata2[:,3] > -9)) * ((gaiadata2[:,3] < -1) + (gaiadata2[:,3] > 1))]\n",
    "    elif filename == \"/data1/users/bpnachman/gaia/gaiascan_l67.5_b74.4_ra208.6_dec35.1.npy\":\n",
    "        gaiadata2 = gaiadata2[((gaiadata2[:,3] < -7) + (gaiadata2[:,3] > -5))]\n",
    "    elif filename == \"/data1/users/bpnachman/gaia/gaiascan_l75.0_b66.4_ra216.0_dec41.0.npy\":\n",
    "        gaiadata2 = gaiadata2[((gaiadata2[:,3] < -14) + (gaiadata2[:,3] > -12))]\n",
    "    elif filename == \"/data1/users/bpnachman/gaia/gaiascan_l99.0_b50.2_ra224.7_dec60.6.npy\":\n",
    "        gaiadata2 = gaiadata2[((gaiadata2[:,3] < 6) + (gaiadata2[:,3] > 7))]\n",
    "    \n",
    "\n",
    "#     plt.hist2d(gaiadata2[:,3],gaiadata2[:,2],bins=[np.linspace(-15,15,100),np.linspace(-15,15,100)],vmin = 0, vmax = 500)\n",
    "#     plt.xlabel(r\"$\\alpha$ [degrees]\")\n",
    "#     plt.ylabel(r\"$\\delta$ [degrees]\")\n",
    "#     plt.savefig('figures/histogram2d' + filename[28:].replace('.', '_') + '.pdf')\n",
    "\n",
    "\n",
    "    \n",
    "    return gaiadata2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plotting \n",
    "# datafile = '/data1/users/bpnachman/gaia/gaiascan_l75.0_b66.4_ra216.0_dec41.0.npy'\n",
    "# gaiadata=np.load(datafile,allow_pickle=True)\n",
    "# gaiadata2 = np.array(gaiadata[:,[9,8,6,7,4,5]]).astype('float32') \n",
    "# gaiadata2 = gaiadata2[np.sum(np.isnan(gaiadata2),axis=1)==0]\n",
    "# center_dec=0.5*(np.max(gaiadata2[:,2])+np.min(gaiadata2[:,2]))\n",
    "# center_ra=0.5*(np.max(gaiadata2[:,3])+np.min(gaiadata2[:,3]))\n",
    "# radius=np.sqrt((gaiadata2[:,2]-center_dec)**2+(gaiadata2[:,3]-center_ra)**2)\n",
    "# gaiadata2=gaiadata2[radius<15]\n",
    "# np.random.shuffle(gaiadata2)\n",
    "# print(len(gaiadata2))\n",
    "# gaiadata2 = gaiadata2[(gaiadata2[:, 0] < 10) * (gaiadata2[:, 0] > 4) * (gaiadata2[:, 1] < 3) * (gaiadata2[:, 1] > -3) * (gaiadata2[:, 4] < 1) * (gaiadata2[:, 4] > 0.5)\n",
    "#                      * (np.abs(gaiadata2[:,0]) > 2) * (np.abs(gaiadata2[:,1]) > 2)]\n",
    "# print(len(gaiadata2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plotting \n",
    "# plt.hist2d(gaiadata2[:,3],gaiadata2[:,2],bins=[np.linspace(-15,15,100),np.linspace(-15,15,100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plotting \n",
    "# plt.scatter(gaiadata2[:,3],gaiadata2[:,2], marker = '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working\n"
     ]
    }
   ],
   "source": [
    "datafiles = [\n",
    "        '/data1/users/bpnachman/gaia/gaiascan_l101.2_b58.4_ra212.7_dec55.2.npy',\n",
    "        '/data1/users/bpnachman/gaia/gaiascan_l22.5_b74.4_ra209.6_dec23.3.npy',\n",
    "        '/data1/users/bpnachman/gaia/gaiascan_l315.0_b66.4_ra197.7_dec4.0.npy',\n",
    "        '/data1/users/bpnachman/gaia/gaiascan_l337.5_b74.4_ra201.9_dec14.0.npy',\n",
    "        '/data1/users/bpnachman/gaia/gaiascan_l45.0_b82.2_ra201.5_dec28.5.npy',\n",
    "        '/data1/users/bpnachman/gaia/gaiascan_l67.5_b74.4_ra208.6_dec35.1.npy',\n",
    "        '/data1/users/bpnachman/gaia/gaiascan_l75.0_b66.4_ra216.0_dec41.0.npy', #best stream \n",
    "        '/data1/users/bpnachman/gaia/gaiascan_l78.8_b58.4_ra224.7_dec46.3.npy',\n",
    "        '/data1/users/bpnachman/gaia/gaiascan_l99.0_b50.2_ra224.7_dec60.6.npy',\n",
    "    ]\n",
    "for datafile in datafiles: \n",
    "    gaiadata=np.load(datafile,allow_pickle=True)\n",
    "    gaiadata2 = np.array(gaiadata[:,[9,8,6,7,4,5]]).astype('float32') \n",
    "    #pm_lat, pm_lon_coslat, lon, lat, color, mag\n",
    "    #4 color 0.5-1\n",
    "    gaiadata2 = gaiadata2[np.sum(np.isnan(gaiadata2),axis=1)==0]\n",
    "    center_dec=0.5*(np.max(gaiadata2[:,2])+np.min(gaiadata2[:,2]))\n",
    "    center_ra=0.5*(np.max(gaiadata2[:,3])+np.min(gaiadata2[:,3]))\n",
    "    radius=np.sqrt((gaiadata2[:,2]-center_dec)**2+(gaiadata2[:,3]-center_ra)**2)\n",
    "    gaiadata2=gaiadata2[radius<15]\n",
    "    np.random.shuffle(gaiadata2)\n",
    "\n",
    "    gaiadata2 = cut_data(datafile, gaiadata2)\n",
    "    gaiadata2 = gaiadata2[(np.abs(gaiadata2[:,0]) > 2) * (np.abs(gaiadata2[:,1]) > 2)]\n",
    "\n",
    "    #apply cut on color on gaiadata2 and send in to build_model\n",
    "    scan_and_plot(gaiadata2, datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# datafile = '/data1/users/bpnachman/gaia/gaiascan_l75.0_b66.4_ra216.0_dec41.0.npy'\n",
    "\n",
    "# pmmin=4\n",
    "# pmmax=10\n",
    "# gaiadata=np.load(datafile,allow_pickle=True)\n",
    "\n",
    "# #pm_lat, pm_lon_coslat, lon, lat, color, mag\n",
    "# gaiadata2=np.array(gaiadata[:,[9,8,6,7,4,5]]).astype('float32')\n",
    "# gaiadata = gaiadata[np.sum(np.isnan(gaiadata2),axis=1)==0]\n",
    "# gaiadata2 = gaiadata2[np.sum(np.isnan(gaiadata2),axis=1)==0]\n",
    "# # Just use radius 15 circle\n",
    "# center_dec=0.5*(np.max(gaiadata2[:,2])+np.min(gaiadata2[:,2]))\n",
    "# center_ra=0.5*(np.max(gaiadata2[:,3])+np.min(gaiadata2[:,3]))\n",
    "# radius=np.sqrt((gaiadata2[:,2]-center_dec)**2+(gaiadata2[:,3]-center_ra)**2)\n",
    "# gaiadata=gaiadata[radius<15]\n",
    "# gaiadata2=gaiadata2[radius<15]\n",
    "# radius=radius[radius<15]\n",
    "# magnitude=gaiadata2[radius<15][:,-1]\n",
    "# color=gaiadata2[radius<15][:,-2]\n",
    "# fidcut= (gaiadata[:,5]<20.2) & (radius<10)\n",
    "# pmlonmask=(gaiadata[:,1]>-3) & (gaiadata[:,1]<3)\n",
    "# colormask=(gaiadata[:,4]>0.5) & (gaiadata[:,4]<1)\n",
    "# pmzero_mask= (np.abs(gaiadata[:,8])>2) | (np.abs(gaiadata[:,9])>2)\n",
    "# pmmask=(gaiadata[:,-1]>pmmin) & (gaiadata[:,-1]<pmmax)\n",
    "# gaiadatatest=gaiadata[fidcut & pmlonmask & pmmask & colormask & pmzero_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(gaiadatatest[:,3], gaiadatatest[:,2], marker = '.')\n",
    "# print(len(gaiadatatest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out regions near 0 (np.abs() > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
