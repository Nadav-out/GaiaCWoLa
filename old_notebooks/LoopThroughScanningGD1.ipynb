{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/shared_env/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_arrays(SR, SB, gaiadata2):\n",
    "    X = SR[:,3]-center_ra\n",
    "    Y = SR[:,2]-center_dec\n",
    "\n",
    "    Xb = SB[:,3]-center_ra\n",
    "    Yb = SB[:,2]-center_dec\n",
    "    \n",
    "    Xad = gaiadata2[:, 3]-center_ra\n",
    "    Yad = gaiadata2[:, 2]-center_dec\n",
    "\n",
    "    SR = np.c_[SR[:,0],SR[:,1],X, Y, SR[:,4],SR[:,5]]\n",
    "    SB = np.c_[SB[:,0],SB[:,1],Xb, Yb, SB[:,4],SB[:,5]]\n",
    "    gaiadata2 = np.c_[gaiadata2[:,0],gaiadata2[:,1], Xad, Yad, gaiadata2[:,4],gaiadata2[:,5]]\n",
    "    \n",
    "    return SR, SB, gaiadata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_arr_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_diff(SR, SB):\n",
    "    return abs(len(SR) - len(SB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_SR_SB_pointers(pointers, increment, data_arr, start_point, end_point):\n",
    "    SR = data_arr[(data_arr[:,0] > pointers[1])*(data_arr[:,0] < pointers[2])]\n",
    "    SB = data_arr[(data_arr[:,0] > pointers[0])*(data_arr[:,0] < pointers[1]) + (data_arr[:,0] > pointers[2])*(data_arr[:,0] < pointers[3])]\n",
    "\n",
    "    previous_diff = calc_diff(SR, SB)\n",
    "    prev_SR, prev_SB = SR, SB\n",
    "    curr_diff = previous_diff\n",
    "    bottom_bool = False\n",
    "    top_bool = True\n",
    "\n",
    "    while curr_diff <= previous_diff and pointers[3] < end_point:\n",
    "        previous_diff, prev_SR, prev_SB = curr_diff, SR, SB\n",
    "        if bottom_bool:\n",
    "            pointers[0] = max(start_point, pointers[0] - increment)\n",
    "        else:\n",
    "            pointers[3] = min(end_point, pointers[3] + increment)\n",
    "        bottom_bool, top_bool = top_bool, bottom_bool\n",
    "        SR = data_arr[(data_arr[:,0] > pointers[1])*(data_arr[:,0] < pointers[2])]\n",
    "        SB = data_arr[(data_arr[:,0] > pointers[0])*(data_arr[:,0] < pointers[1]) + (data_arr[:,0] > pointers[2])*(data_arr[:,0] < pointers[3])]\n",
    "        curr_diff = calc_diff(SR, SB)\n",
    "\n",
    "    return prev_SR, prev_SB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(SR, SB, num_models, all_data, pointers, colors, filename, iter_num):\n",
    "    \n",
    "    X = np.concatenate([SR,SB])\n",
    "    Y = np.concatenate([np.ones(len(SR)),np.zeros(len(SB))])\n",
    "\n",
    "    myscalar = preprocessing.StandardScaler()\n",
    "    myscalar.fit(X)\n",
    "    X_scaled = myscalar.transform(X)\n",
    "    all_data_scaled = myscalar.transform(all_data)\n",
    "\n",
    "    X_scaled = X_scaled[Y<2]\n",
    "    Y = Y[Y<2]\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.5)\n",
    "\n",
    "\n",
    "    for i in range(num_models):\n",
    "        \n",
    "        print('working')\n",
    "        model = Sequential()\n",
    "        initializer =tf.keras.initializers.glorot_normal()\n",
    "        model.add(Dense(64, input_dim=5, activation='relu', bias_initializer = initializer)) \n",
    "        model.add(Dense(64, activation='relu', bias_initializer = initializer))\n",
    "        model.add(Dense(64, activation='relu', bias_initializer = initializer))\n",
    "        model.add(Dense(1, activation='sigmoid', bias_initializer = initializer))\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        history = model.fit(X_train[:,1:],Y_train, epochs=20, batch_size=200,validation_data=(X_test[:,1:],Y_test), verbose = 0) \n",
    "\n",
    "        preds = model.predict(X_test[:,1:], batch_size=int(0.1*len(X_test)))\n",
    "        preds_all = model.predict(all_data_scaled[:, 1:]) \n",
    "        \n",
    "        cuts = [0.,0.5,0.9,0.99, 0.999]\n",
    "        plt.figure(figsize = (12, 12))\n",
    "        plt.yscale('log')\n",
    "        plt.ylim([1, 10e5])\n",
    "        plt.axvline(pointers[1], color = 'black')\n",
    "        plt.axvline(pointers[2], color = 'black')\n",
    "        plt.axvline(pointers[0], color = 'gray')\n",
    "        plt.axvline(pointers[3], color = 'gray')\n",
    "        title_str = 'Cuts on pmdec'\n",
    "        plt.ylabel('Counts', fontsize = 20)\n",
    "        plt.xlabel('PMDEC', fontsize= 20)\n",
    "        stars_passing_cut = []\n",
    "        for j in range(len(cuts)):\n",
    "            cut = cuts[j]\n",
    "            X_unscaled = myscalar.inverse_transform(X_scaled[:, :6])\n",
    "            all_data_unscaled = myscalar.inverse_transform(all_data_scaled[:, :6])\n",
    "            X_pass_all = all_data_unscaled[(preds_all[:,0] > np.quantile(preds[Y_test==1],[cut])[0])]\n",
    "            plt.hist(X_pass_all[:,0], bins = np.linspace(-30, 15, 100), color = colors[j], alpha = 1, histtype = 'step', label = str(cut*100) + 'th Percentile')\n",
    "            if cut == 0.99:\n",
    "                stars_passing_cut = X_pass_all[(X_pass_all[:,0] > pointers[1]) * (X_pass_all[:,0] < pointers[2])]\n",
    "        plt.text((pointers[1] + pointers[2])/2, 1e5, 'SR', fontsize = 20)\n",
    "        plt.legend()\n",
    "        plt.savefig('figures_gd1_radec_cut/scanning_plots' + filename + '_' + str(iter_num) + '.pdf')\n",
    "        plt.clf()\n",
    "        \n",
    "        plt.figure(figsize = (12, 12))\n",
    "        plt.hist2d(stars_passing_cut[:,3],stars_passing_cut[:,2],bins=[np.linspace(-15,15,100),np.linspace(-15,15,100)])\n",
    "        plt.savefig('figures_gd1_radec_cut/stars_passing_cut' + filename + '_' + str(iter_num) + '.pdf')\n",
    "        plt.clf()\n",
    "        \n",
    "        plt.figure(figsize = (12, 12))\n",
    "        plt.yscale('log')\n",
    "        plt.ylim([1, 10e5])\n",
    "        plt.ylabel('Counts', fontsize = 20)\n",
    "        plt.xlabel('PMRA', fontsize= 20)\n",
    "        plt.hist(stars_passing_cut[:,1], bins = np.linspace(-30, 15, 100), alpha = 1, histtype = 'step', label = '99th Percentile')\n",
    "        plt.savefig('figures_gd1_radec_cut/stars_passing_cut_rahist' + filename + '_' + str(iter_num) + '.pdf')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_and_plot(gaiadata2, filename):\n",
    "    iter_num = 0\n",
    "    start_point = min(gaiadata2[:,0])\n",
    "    pointers = np.zeros(4)\n",
    "    signal_size = 4\n",
    "    signal_increment = 2\n",
    "    sb_start_diff = 0.5\n",
    "    pointers[0] = start_point\n",
    "    pointers[1] = start_point + sb_start_diff\n",
    "    pointers[2] = pointers[1] + signal_size\n",
    "    pointers[3] = pointers[2] + sb_start_diff\n",
    "    end_point = max(gaiadata2[:,0])\n",
    "    colors = ['red', 'orange', 'green', 'blue', 'purple']\n",
    "\n",
    "    while pointers[3] <= end_point:\n",
    "        SR, SB = find_SR_SB_pointers(pointers, sb_start_diff, gaiadata2, start_point, end_point)\n",
    "        if len(SR) >= threshold_arr_size:\n",
    "            SR, SB, all_data = build_data_arrays(SR, SB, gaiadata2)\n",
    "            build_model(SR, SB, 1, all_data, pointers, colors, filename, iter_num)\n",
    "            iter_num += 1\n",
    "        pointers[1] += signal_increment\n",
    "        pointers[2] += signal_increment\n",
    "        pointers[0] = pointers[1] - sb_start_diff\n",
    "        pointers[3] = pointers[2] + sb_start_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-62258bdc3d4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdatafile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/data0/users/bpnachman/Gaia/GD1-circle-140-30-15.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgaiadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgaiadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgaiadata2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaiadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pmdec'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pmra'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dec'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ra'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'phot_g_mean_mag'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'phot_bp_mean_mag'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'phot_rp_mean_mag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'streammask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m gaiadata2 = np.vstack([gaiadata2[:,0].T,\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "datafile = \"/data0/users/bpnachman/Gaia/GD1-circle-140-30-15.pkl\"\n",
    "gaiadata=np.load(datafile,allow_pickle=True)\n",
    "gaiadata=np.load(datafile,allow_pickle=True)\n",
    "gaiadata2=np.array(gaiadata[['pmdec','pmra','dec','ra','phot_g_mean_mag','phot_bp_mean_mag','phot_rp_mean_mag', 'streammask']].astype('float32'))\n",
    "gaiadata2 = np.vstack([gaiadata2[:,0].T,\n",
    "           gaiadata2[:,1].T,\n",
    "           gaiadata2[:,2].T,\n",
    "           gaiadata2[:,3].T,\n",
    "           (gaiadata2[:,5]-gaiadata2[:,6]).T,\n",
    "           gaiadata2[:,4].T, \n",
    "            gaiadata2[:,7].T]).T\n",
    "gaiadata2 = gaiadata2[np.sum(np.isnan(gaiadata2),axis=1)==0]\n",
    "center_dec=0.5*(np.max(gaiadata2[:,2])+np.min(gaiadata2[:,2]))\n",
    "center_ra=0.5*(np.max(gaiadata2[:,3])+np.min(gaiadata2[:,3]))\n",
    "radius=np.sqrt((gaiadata2[:,2]-center_dec)**2+(gaiadata2[:,3]-center_ra)**2)\n",
    "gaiadata2=gaiadata2[radius<15]\n",
    "np.random.shuffle(gaiadata2) \n",
    "gaiadata2 = gaiadata2[(np.abs(gaiadata2[:,0]) > 2) + (np.abs(gaiadata2[:,1]) > 2)]\n",
    "#cut out abs(pmdec & pmra) <= 2\n",
    "#overlay gd1 stars\n",
    "scan_and_plot(gaiadata2, \"_GD1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
